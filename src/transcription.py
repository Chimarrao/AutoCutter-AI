#!/usr/bin/env python3
"""
M√≥dulo de transcri√ß√£o para AutoCutter-AI
Cont√©m fun√ß√µes de transcri√ß√£o de v√≠deo e gera√ß√£o de legendas
"""

import os
import sys
import threading
import subprocess
import queue
import json
import tempfile
import shutil
from datetime import timedelta

def check_ffmpeg():
    """Verificar se ffmpeg est√° instalado e dispon√≠vel"""
    try:
        result = subprocess.run(['ffmpeg', '-version'],
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            # Extrair vers√£o
            version_line = result.stdout.split('\n')[0]
            return True, version_line
        else:
            return False, "FFmpeg n√£o encontrado"
    except (subprocess.TimeoutExpired, FileNotFoundError, subprocess.SubprocessError) as e:
        return False, f"Erro ao verificar FFmpeg: {str(e)}"

def format_timestamp(seconds):
    """Converter segundos para formato de timestamp SRT (HH:MM:SS,mmm)"""
    td = timedelta(seconds=seconds)
    hours, remainder = divmod(td.seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    milliseconds = td.microseconds // 1000
    return "02d"

def generate_srt(segments):
    """Gerar conte√∫do SRT a partir de segmentos do Whisper"""
    srt_content = []
    for i, segment in enumerate(segments, 1):
        start_time = format_timestamp(segment['start'])
        end_time = format_timestamp(segment['end'])
        text = segment['text'].strip()

        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")  # Linha em branco

    return "\n".join(srt_content)

def generate_ass(segments, video_width=1920, video_height=1080):
    """Gerar conte√∫do ASS a partir de segmentos do Whisper"""
    ass_header = f"""[Script Info]
Title: AutoCutter-AI Transcription
ScriptType: v4.00+
WrapStyle: 0
ScaledBorderAndShadow: yes
YCbCr Matrix: TV.601

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,Arial,48,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,2,2,2,30,30,30,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

    ass_events = []
    for segment in segments:
        start_time = format_timestamp(segment['start']).replace(',', '.')
        end_time = format_timestamp(segment['end']).replace(',', '.')
        text = segment['text'].strip()

        ass_events.append(f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}")

    return ass_header + "\n".join(ass_events)

def extract_audio(video_path, output_audio_path):
    """Extrair √°udio do v√≠deo usando ffmpeg"""
    try:
        cmd = [
            'ffmpeg', '-i', video_path,
            '-vn',  # Sem v√≠deo
            '-acodec', 'pcm_s16le',  # PCM 16-bit
            '-ar', '16000',  # 16kHz sample rate (ideal para Whisper)
            '-ac', '1',  # Mono
            '-y',  # Sobrescrever
            output_audio_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.returncode == 0, result.stderr if result.returncode != 0 else None

    except Exception as e:
        return False, str(e)

def run_whisper_transcription(audio_path, model="base", device="cpu", language=None):
    """Executar transcri√ß√£o usando Whisper"""
    try:
        import whisper

        # Carregar modelo
        model_obj = whisper.load_model(model, device=device)

        # Configurar op√ß√µes
        options = {}
        if language:
            options['language'] = language

        # Transcrever
        result = model_obj.transcribe(audio_path, **options)

        return True, result

    except ImportError:
        return False, "Whisper n√£o instalado. Instale com: pip install openai-whisper"
    except Exception as e:
        return False, f"Erro na transcri√ß√£o: {str(e)}"

def render_video_with_subtitles(video_path, subtitle_path, output_path, quality="1080p 30fps"):
    """Renderizar v√≠deo com legendas usando ffmpeg"""
    try:
        # Mapear qualidade para configura√ß√µes ffmpeg
        quality_map = {
            "4K 30fps": ("3840:2160", "30"),
            "1080p 60fps": ("1920:1080", "60"),
            "1080p 30fps": ("1920:1080", "30"),
            "720p 60fps": ("1280:720", "60"),
            "720p 30fps": ("1280:720", "30"),
            "480p 30fps": ("854:480", "30")
        }

        scale, fps = quality_map.get(quality, ("1920:1080", "30"))

        # Detectar formato da legenda
        subtitle_ext = os.path.splitext(subtitle_path)[1].lower()

        if subtitle_ext == '.srt':
            subtitle_filter = f"subtitles='{subtitle_path}':force_style='FontSize=24,PrimaryColour=&HFFFFFF&,OutlineColour=&H000000&,BorderStyle=1,Outline=2'"
        elif subtitle_ext == '.ass':
            subtitle_filter = f"ass='{subtitle_path}'"
        else:
            return False, "Formato de legenda n√£o suportado. Use .srt ou .ass"

        cmd = [
            'ffmpeg', '-i', video_path,
            '-vf', f"scale={scale},{subtitle_filter}",
            '-r', fps,
            '-c:v', 'libx264',
            '-preset', 'slow',
            '-crf', '18',
            '-c:a', 'aac',
            '-b:a', '192k',
            '-y',
            output_path
        ]

        result = subprocess.run(cmd, capture_output=True, text=True)
        return result.returncode == 0, result.stderr if result.returncode != 0 else None

    except Exception as e:
        return False, str(e)

def start_transcription(gui_instance):
    """Iniciar processo de transcri√ß√£o"""
    # Validar entrada
    if not gui_instance.transcription_video_path:
        gui_instance.output_queue.put(("transcription_error", "Selecione um arquivo de v√≠deo para transcri√ß√£o!"))
        return

    if not os.path.exists(gui_instance.transcription_video_path):
        gui_instance.output_queue.put(("transcription_error", "O arquivo de v√≠deo n√£o existe!"))
        return

    # Verificar ffmpeg
    ffmpeg_ok, ffmpeg_msg = check_ffmpeg()
    if not ffmpeg_ok:
        gui_instance.output_queue.put(("transcription_error", f"FFmpeg n√£o encontrado: {ffmpeg_msg}"))
        return

    # Iniciar thread de transcri√ß√£o
    thread = threading.Thread(
        target=transcription_thread,
        args=(gui_instance,),
        daemon=True
    )
    thread.start()

def transcription_thread(gui_instance):
    """Thread para processar transcri√ß√£o"""
    try:
        gui_instance.output_queue.put(("transcription_status", "üîÑ Iniciando transcri√ß√£o..."))
        gui_instance.output_queue.put(("transcription_progress", 5))

        # Extrair √°udio
        gui_instance.output_queue.put(("transcription_status", "üéµ Extraindo √°udio do v√≠deo..."))
        gui_instance.output_queue.put(("transcription_progress", 20))

        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as temp_audio:
            temp_audio_path = temp_audio.name

        success, error = extract_audio(gui_instance.transcription_video_path, temp_audio_path)
        if not success:
            gui_instance.output_queue.put(("transcription_error", f"Erro ao extrair √°udio: {error}"))
            return

        gui_instance.output_queue.put(("transcription_progress", 40))

        # Executar Whisper
        model = gui_instance.transcription_model_combo.currentText()
        device = "cuda" if gui_instance.transcription_gpu_check.isChecked() else "cpu"

        gui_instance.output_queue.put(("transcription_status", f"üé§ Transcrevendo com Whisper ({model})..."))
        gui_instance.output_queue.put(("transcription_progress", 60))

        success, result = run_whisper_transcription(temp_audio_path, model=model, device=device)
        if not success:
            gui_instance.output_queue.put(("transcription_error", result))
            return

        gui_instance.output_queue.put(("transcription_progress", 80))

        # Processar resultados
        segments = result['segments']
        full_text = result['text']

        # Salvar segmentos para uso posterior
        gui_instance.transcription_segments = segments
        gui_instance.transcription_text = full_text

        # Atualizar interface
        gui_instance.output_queue.put(("transcription_progress", 100))
        gui_instance.output_queue.put(("transcription_status", "‚úÖ Transcri√ß√£o conclu√≠da!"))
        gui_instance.output_queue.put(("transcription_result", segments))

        # Limpar arquivo tempor√°rio
        try:
            os.unlink(temp_audio_path)
        except:
            pass

    except Exception as e:
        gui_instance.output_queue.put(("transcription_error", f"Erro na transcri√ß√£o: {str(e)}"))

def start_video_render(gui_instance):
    """Iniciar renderiza√ß√£o de v√≠deo com legendas"""
    if not gui_instance.transcription_video_path:
        gui_instance.output_queue.put(("render_error", "Selecione um v√≠deo para renderizar!"))
        return

    if not hasattr(gui_instance, 'transcription_segments') or not gui_instance.transcription_segments:
        gui_instance.output_queue.put(("render_error", "Execute a transcri√ß√£o primeiro!"))
        return

    # Verificar ffmpeg
    ffmpeg_ok, ffmpeg_msg = check_ffmpeg()
    if not ffmpeg_ok:
        gui_instance.output_queue.put(("render_error", f"FFmpeg n√£o encontrado: {ffmpeg_msg}"))
        return

    # Iniciar thread de renderiza√ß√£o
    thread = threading.Thread(
        target=render_thread,
        args=(gui_instance,),
        daemon=True
    )
    thread.start()

def render_thread(gui_instance):
    """Thread para renderizar v√≠deo com legendas"""
    try:
        gui_instance.output_queue.put(("render_status", "üé¨ Iniciando renderiza√ß√£o..."))

        # Criar arquivo de legenda tempor√°rio
        with tempfile.NamedTemporaryFile(mode='w', suffix='.srt', delete=False, encoding='utf-8') as temp_sub:
            temp_sub_path = temp_sub.name
            srt_content = generate_srt(gui_instance.transcription_segments)
            temp_sub.write(srt_content)

        # Definir caminho de sa√≠da
        base_name = os.path.splitext(os.path.basename(gui_instance.transcription_video_path))[0]
        quality = gui_instance.render_quality_combo.currentText().replace(' ', '_')
        output_path = os.path.join("saida", f"{base_name}_com_legendas_{quality}.mp4")

        # Renderizar
        gui_instance.output_queue.put(("render_status", "üé¨ Renderizando v√≠deo com legendas..."))

        success, error = render_video_with_subtitles(
            gui_instance.transcription_video_path,
            temp_sub_path,
            output_path,
            gui_instance.render_quality_combo.currentText()
        )

        # Limpar arquivo tempor√°rio
        try:
            os.unlink(temp_sub_path)
        except:
            pass

        if success:
            gui_instance.output_queue.put(("render_status", f"‚úÖ V√≠deo renderizado: {output_path}"))
            gui_instance.output_queue.put(("render_success", output_path))
        else:
            gui_instance.output_queue.put(("render_error", f"Erro na renderiza√ß√£o: {error}"))

    except Exception as e:
        gui_instance.output_queue.put(("render_error", f"Erro na renderiza√ß√£o: {str(e)}"))